"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[21565],{1418:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>r,toc:()=>m});var n=a(87462),l=(a(67294),a(3905));const i={sidebar_position:1},o="Deploy llama-2 on AWS",r={unversionedId:"tutorials/llama2-on-aws",id:"tutorials/llama2-on-aws",title:"Deploy llama-2 on AWS",description:"This tutorial demonstrates how to deploy llama-2 using Walrus on AWS with CPU, and utilize it through a user-friendly web UI.",source:"@site/docs/tutorials/llama2-on-aws.md",sourceDirName:"tutorials",slug:"/tutorials/llama2-on-aws",permalink:"/docs/tutorials/llama2-on-aws",draft:!1,editUrl:"https://github.com/seal-io/docs/edit/main/docs/tutorials/llama2-on-aws.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"docs",previous:{title:"Create a Catalog on GitHub",permalink:"/docs/tutorials/catalog-on-github"},next:{title:"Integration with CI/CD Tools",permalink:"/docs/tutorials/integrate-with-cicd"}},s={},m=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"The Simple Way",id:"the-simple-way",level:2},{value:"Add the llama-2 Template",id:"add-the-llama-2-template",level:3},{value:"Configure AWS Credentials",id:"configure-aws-credentials",level:3},{value:"Configure Environment",id:"configure-environment",level:3},{value:"Create the llama-2 Service",id:"create-the-llama-2-service",level:3},{value:"Accessing the llama-2 Web UI",id:"accessing-the-llama-2-web-ui",level:3},{value:"Deep Dive: Building the llama-2 Image from Scratch",id:"deep-dive-building-the-llama-2-image-from-scratch",level:2}],d={toc:m};function c(e){let{components:t,...i}=e;return(0,l.kt)("wrapper",(0,n.Z)({},d,i,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"deploy-llama-2-on-aws"},"Deploy llama-2 on AWS"),(0,l.kt)("p",null,"This tutorial demonstrates how to deploy llama-2 using Walrus on AWS with CPU, and utilize it through a user-friendly web UI."),(0,l.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,l.kt)("p",null,"To follow this tutorial, you will need:"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"An AWS account with associated ",(0,l.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html"},"credentials"),", and sufficient permissions to create EC2 instances."),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("a",{parentName:"li",href:"/deploy/standalone"},"Walrus installed"),".")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Note:\nWhile using CPU is cheaper than GPU, it still incurs costs corresponding to the EC2 instance.")),(0,l.kt)("h2",{id:"the-simple-way"},"The Simple Way"),(0,l.kt)("p",null,"With Walrus, you can have a running llama-2 instance on AWS with a user-friendly web UI in about a minute. Just follow these steps:"),(0,l.kt)("h3",{id:"add-the-llama-2-template"},"Add the llama-2 Template"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Log in to Walrus, click on ",(0,l.kt)("inlineCode",{parentName:"li"},"Operations")," in the left navigation, go to the ",(0,l.kt)("inlineCode",{parentName:"li"},"Templates")," tab, and click the ",(0,l.kt)("inlineCode",{parentName:"li"},"New Template")," button."),(0,l.kt)("li",{parentName:"ol"},"Enter a template name, e.g., ",(0,l.kt)("inlineCode",{parentName:"li"},"llama-2"),"."),(0,l.kt)("li",{parentName:"ol"},"In the source field, enter ",(0,l.kt)("inlineCode",{parentName:"li"},"https://github.com/walrus-tutorials/llama2-on-aws"),"."),(0,l.kt)("li",{parentName:"ol"},"Click ",(0,l.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"llama2-add-template",src:a(31786).Z,width:"3826",height:"1972"})),(0,l.kt)("h3",{id:"configure-aws-credentials"},"Configure AWS Credentials"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"In the left navigation, click on ",(0,l.kt)("inlineCode",{parentName:"li"},"Operations")," and click the ",(0,l.kt)("inlineCode",{parentName:"li"},"Connectors")," tab."),(0,l.kt)("li",{parentName:"ol"},"Click the ",(0,l.kt)("inlineCode",{parentName:"li"},"New Connector")," button and select the ",(0,l.kt)("inlineCode",{parentName:"li"},"Cloud Provider")," type."),(0,l.kt)("li",{parentName:"ol"},"Enter a connector name, e.g., ",(0,l.kt)("inlineCode",{parentName:"li"},"aws"),"."),(0,l.kt)("li",{parentName:"ol"},"Choose ",(0,l.kt)("inlineCode",{parentName:"li"},"Development")," for the ",(0,l.kt)("inlineCode",{parentName:"li"},"Applicable Environment Type")," option."),(0,l.kt)("li",{parentName:"ol"},"Choose ",(0,l.kt)("inlineCode",{parentName:"li"},"AWS")," for the ",(0,l.kt)("inlineCode",{parentName:"li"},"Type")," option."),(0,l.kt)("li",{parentName:"ol"},"Select ",(0,l.kt)("inlineCode",{parentName:"li"},"Tokyo (ap-northeast-1)")," for the ",(0,l.kt)("inlineCode",{parentName:"li"},"Region")," option."),(0,l.kt)("li",{parentName:"ol"},"Click ",(0,l.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Note:\nThe specified region is used here because the subsequent steps involve using an AMI from that region. If you want to use a different region, you can export the AMI to your region or refer to the following sections on how to build the llama-2 image from scratch.")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"llama2-add-connector",src:a(89776).Z,width:"3824",height:"1960"})),(0,l.kt)("h3",{id:"configure-environment"},"Configure Environment"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"In the left navigation, click on ",(0,l.kt)("inlineCode",{parentName:"li"},"Applications")," and click the ",(0,l.kt)("inlineCode",{parentName:"li"},"default")," project in breadcrumb on the top."),(0,l.kt)("li",{parentName:"ol"},"In the ",(0,l.kt)("inlineCode",{parentName:"li"},"Environments")," tab, click the ",(0,l.kt)("inlineCode",{parentName:"li"},"New Environment")," button."),(0,l.kt)("li",{parentName:"ol"},"Enter an environment name, e.g., ",(0,l.kt)("inlineCode",{parentName:"li"},"dev"),"."),(0,l.kt)("li",{parentName:"ol"},"Choose ",(0,l.kt)("inlineCode",{parentName:"li"},"Development")," for the ",(0,l.kt)("inlineCode",{parentName:"li"},"Environment Type")," option."),(0,l.kt)("li",{parentName:"ol"},"Click the ",(0,l.kt)("inlineCode",{parentName:"li"},"Add Connector")," button and select the ",(0,l.kt)("inlineCode",{parentName:"li"},"aws")," connector created in the previous step."),(0,l.kt)("li",{parentName:"ol"},"Click ",(0,l.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"llama2-add-environment",src:a(65023).Z,width:"3822",height:"1970"})),(0,l.kt)("h3",{id:"create-the-llama-2-service"},"Create the llama-2 Service"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"In the ",(0,l.kt)("inlineCode",{parentName:"li"},"Environments")," tab, click on the name of the ",(0,l.kt)("inlineCode",{parentName:"li"},"dev")," environment to enter its view."),(0,l.kt)("li",{parentName:"ol"},"Click the ",(0,l.kt)("inlineCode",{parentName:"li"},"New Resource")," button."),(0,l.kt)("li",{parentName:"ol"},"Enter a resource name, e.g., ",(0,l.kt)("inlineCode",{parentName:"li"},"my-llama-2"),"."),(0,l.kt)("li",{parentName:"ol"},"Enable the ",(0,l.kt)("inlineCode",{parentName:"li"},"Use Template")," option."),(0,l.kt)("li",{parentName:"ol"},"Choose ",(0,l.kt)("inlineCode",{parentName:"li"},"llama-2")," in the ",(0,l.kt)("inlineCode",{parentName:"li"},"Template")," option."),(0,l.kt)("li",{parentName:"ol"},"Click ",(0,l.kt)("inlineCode",{parentName:"li"},"Save"),".")),(0,l.kt)("blockquote",null,(0,l.kt)("p",{parentName:"blockquote"},"Note:\nThe default configuration assumes your AWS account has a default VPC in the corresponding region. If you don't have a default VPC, create a new VPC, associate a subnet and a security group with it in the AWS VPC console.\nThe security group needs to open port 7860 TCP (for accessing the llama-2 web UI). You can set your VPC name and security group name in the configuration.")),(0,l.kt)("h3",{id:"accessing-the-llama-2-web-ui"},"Accessing the llama-2 Web UI"),(0,l.kt)("p",null,"You can see the deployment and running status of the llama-2 service on its details page. Once the llama-2 service deployment is completed, you can access its web UI by clicking the access link of the resource in the Walrus UI."),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"llama2-resource-detail",src:a(35708).Z,width:"3820",height:"1948"})),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"llama2-webui",src:a(83045).Z,width:"3538",height:"1840"})),(0,l.kt)("h2",{id:"deep-dive-building-the-llama-2-image-from-scratch"},"Deep Dive: Building the llama-2 Image from Scratch"),(0,l.kt)("p",null,"The above instructions utilized a pre-built llama-2 image. This approach saves time as you don't need to download the large language model (often with a significant file size) or build the inference service when creating a new llama-2 instance.\nThis section explains how such a llama-2 image is built."),(0,l.kt)("p",null,"You can find the complete build process ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/walrus-tutorials/llama2-on-aws/blob/build/main.tf"},"here"),"."),(0,l.kt)("p",null,"Key steps include:"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-shell"},"# get text-generation-webui\ngit clone https://github.com/oobabooga/text-generation-webui && cd text-generation-webui\n# configure text-generation-webui\nln -s docker/{Dockerfile,docker-compose.yml,.dockerignore} .\ncp docker/.env.example .env\nsed -i '/^CLI_ARGS=/s/.*/CLI_ARGS=--model llama-2-7b-chat.ggmlv3.q4_K_M.bin --wbits 4 --listen --auto-devices/' .env\nsed -i '/^\\s*deploy:/,$d' docker/docker-compose.yml\n# get quantized llama-2\ncurl -L https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_K_M.bin --output ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin\n# build and run\ndocker compose up --build\n")),(0,l.kt)("p",null,"In essence, this process downloads the quantized llama-2-7b-chat model, then builds and utilizes text-generation-webui to launch the llama-2 service."))}c.isMDXComponent=!0},89776:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/llama2-add-connector-71e853c72bb3f37b3e38f686619d3178.png"},65023:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/llama2-add-environment-95af8f1cad6b66e9605b91ec378131fe.png"},31786:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/llama2-add-template-e4d630de9367eebe84a05eb753bc9d09.png"},35708:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/llama2-resource-detail-52a96748e581c8290d6e6ddbe9e3092a.png"},83045:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/llama2-web-ui-1d82a84f88f74bd6e3add858afa5e0b8.png"}}]);